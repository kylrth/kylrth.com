<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>alignment on Kyle Roth</title><link>https://kylrth.com/tags/alignment/</link><description>Recent content in alignment on Kyle Roth</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 17 Apr 2023 10:07:35 -0400</lastBuildDate><atom:link href="https://kylrth.com/tags/alignment/index.xml" rel="self" type="application/rss+xml"/><item><title>the NYT AI explainer misses the point</title><link>https://kylrth.com/post/nyt-ai-explainer/</link><pubDate>Mon, 17 Apr 2023 10:07:35 -0400</pubDate><guid>https://kylrth.com/post/nyt-ai-explainer/</guid><description>In late March 2023, the NYT released a series of explainer articles about AI. The first article in the seriesYou can also read it on Archive.org if you don&amp;rsquo;t have a subscription. characterizes the recent history of AI as a progression of new technological ideas appearing over time. Of course that&amp;rsquo;s partially true, but it gets the order wrong and misses important non-technical events that are key to understanding our current position.</description></item><item><title>the inherent subjectivity of reality</title><link>https://kylrth.com/post/edward-frenkel/</link><pubDate>Fri, 14 Apr 2023 14:45:44 -0400</pubDate><guid>https://kylrth.com/post/edward-frenkel/</guid><description>These are some thoughts I&amp;rsquo;ve had while listening to a Lex Fridman interview with Edward Frenkel, a mathematician at UC Berkeley working on mathematical quantum physics.
In the information age, we like to see everything as computation. But what do we mean when we say that something is computation? We mean that a physical system with predictable interactions has a meaningful result. If we somehow learned that the universe was computational in nature, the only thing that adds is that the universe&amp;rsquo;s state is meaningful somehow.</description></item><item><title>for a socially beneficial and responsible development of AI</title><link>https://kylrth.com/post/bengio-crawford/</link><pubDate>Mon, 20 Mar 2023 14:04:51 -0400</pubDate><guid>https://kylrth.com/post/bengio-crawford/</guid><description>These are my notes from a conversation between Yoshua Bengio and Kate Crawford held at Mila on 2023-03-20, announcing the release of a new book created as a joint report between Mila and UNESCO called Missing links in AI governance (link). There were news articles in French (Le Devoir), but not as many in English unfortunately (Datanami).
Bengio: What motivates you to do what you do? This topic has turned from an academic move to a societal one really quickly, and it&amp;rsquo;s scary.</description></item><item><title>Army of none: autonomous weapons and the future of war</title><link>https://kylrth.com/book/army-of-none/</link><pubDate>Tue, 14 Feb 2023 13:33:19 -0500</pubDate><guid>https://kylrth.com/book/army-of-none/</guid><description>The examples in this book make it clear that there is no easy line we can draw between autonomous and non-autonomous weapons (and by extension, autonomous AI agents). There is a smooth gradient of autonomy, which makes the question of allowing autonomous weapons much more nuanced. It&amp;rsquo;s probably the case that higher-level alignment becomes important proportionally to the level of autonomy and intelligence.
He analyzes the Patriot fratricides,In a military context, the word fratricide means the killing of someone on the same side of a conflict.</description></item><item><title>Artificial intelligence, values, and alignment</title><link>https://kylrth.com/paper/ai-values-alignment/</link><pubDate>Fri, 10 Feb 2023 08:09:15 -0500</pubDate><guid>https://kylrth.com/paper/ai-values-alignment/</guid><description>I presented this paper in Bang Liu&amp;rsquo;s research group meeting in two installments on 2023-02-20 and 2023-02-27, and also in Irina Rish&amp;rsquo;s scaling and alignment course (IFT6760A) on 2023-03-07. You can view the slides I used here.The thumbnail for this post was generated with stable diffusion! See the alt text for details.
Behind each vision for ethically-aligned AI sits a deeper question. How are we to decide which principles or objectives to encode in AI—and who has the right to make these decisions—given that we live in a pluralistic world that is full of competing conceptions of value?</description></item><item><title>Unsolved problems in ML safety</title><link>https://kylrth.com/paper/unsolved-problems-ml-safety/</link><pubDate>Mon, 06 Feb 2023 11:39:33 -0500</pubDate><guid>https://kylrth.com/paper/unsolved-problems-ml-safety/</guid><description>This was a paper we presented about in Irina Rish&amp;rsquo;s neural scaling laws course (IFT6760A) in winter 2023. You can view the slides we used here, and the recording here (or my backup here).</description></item></channel></rss>